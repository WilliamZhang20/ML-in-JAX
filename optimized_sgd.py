import numpy as np
from jax import jit
from jax import vmap
from jax import random
import jax
import jax.numpy as jnp

"""
Applying optimizations to gradient descent such as:
- Momentum with SGD
- RMSProp
- Learning Rate Scheduling
- Adam
"""

